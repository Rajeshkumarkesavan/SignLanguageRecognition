{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f538e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e0c2b4",
   "metadata": {},
   "source": [
    "# ignore//to isolate the hand region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41db59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2)\n",
    "i = 0\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    #cv2.imshow('webcam', frame)\n",
    "    cv2.imwrite('captures/'+str(i)+'.jpg',frame)\n",
    "    i+=1\n",
    "    if cv2.waitKey(1)&0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59fc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "# global variables\n",
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# To find the running average over the background\n",
    "#--------------------------------------------------\n",
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e63285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------\n",
    "# To segment the region of hand in the image\n",
    "#---------------------------------------------\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (_, cnts, _) = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------\n",
    "# MAIN FUNCTION\n",
    "#-----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize weight for running average\n",
    "    aWeight = 0.5\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "    # keep looping, until interrupted\n",
    "    while(True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "\n",
    "        # resize the frame\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "\n",
    "        # flip the frame so that it is not the mirror view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # clone the frame\n",
    "        clone = frame.copy()\n",
    "\n",
    "        # get the height and width of the frame\n",
    "        (height, width) = frame.shape[:2]\n",
    "\n",
    "        # get the ROI\n",
    "        roi = frame[top:bottom, right:left]\n",
    "\n",
    "        # convert the roi to grayscale and blur it\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # to get the background, keep looking till a threshold is reached\n",
    "        # so that our running average model gets calibrated\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, aWeight)\n",
    "        else:\n",
    "            # segment the hand region\n",
    "            hand = segment(gray)\n",
    "\n",
    "            # check whether hand region is segmented\n",
    "            if hand is not None:\n",
    "                # if yes, unpack the thresholded image and\n",
    "                # segmented region\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                # draw the segmented region and display the frame\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                #cv2.imshow(\"Thesholded\", thresholded)\n",
    "                cv2.imwrite('captures/'+str(num_frames)+'.jpg',thresholded)\n",
    "\n",
    "        # draw the segmented hand\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "        # increment the number of frames\n",
    "        num_frames += 1\n",
    "\n",
    "        # display the frame with segmented hand\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "        \n",
    "\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the user pressed \"q\", then stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "# free up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d78a9a",
   "metadata": {},
   "source": [
    "# live video capture with mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1363675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b58c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d74eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34236ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "        # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                  image,\n",
    "                  hand_landmarks,\n",
    "                  mp_hands.HAND_CONNECTIONS,\n",
    "                  mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                  mp_drawing_styles.get_default_hand_connections_style())\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d6fb9",
   "metadata": {},
   "source": [
    "# preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"asl/amer_sign2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "train = pd.read_csv('asl/sign_mnist_train.csv')\n",
    "test = pd.read_csv('asl/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f085a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping the label coloumn from the training set\n",
    "train.drop('label', axis = 1, inplace = True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.values.reshape(train.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ec74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673eaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"cropped/0.png\",x_train[0].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cff031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(x_train):\n",
    "    for i in range(len(x_train)):\n",
    "        plt.imsave(\"cropped/cropped\"+str(i)+\".png\",x_train[i].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ffec1",
   "metadata": {},
   "source": [
    "# images belong to the same folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop thru all the files in a folder \n",
    "filenames = []\n",
    "directory = '/Users/bridgetliu/project/mais2021/archive/asl_alphabet_train/asl_alphabet_train/K'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        filenames.append(os.path.join(directory, filename))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a76c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641be06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "IMAGE_FILES = filenames\n",
    "#IMAGE_FILES = [\"archive/asl_alphabet_train/asl_alphabet_train/K/K294.jpg\"]\n",
    "#IMAGE_FILES = [\"test.jpg\"]\n",
    "all_img_features = []\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        print(\"here\")\n",
    "        featurelist = []\n",
    "        # Read an image, flip it around y-axis for correct handedness output\n",
    "        image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        #results = hands.process(image)\n",
    "        #Print handedness and draw hand landmarks on the image.\n",
    "        featurelist.append('k')\n",
    "        featurelist.append(results.multi_handedness)\n",
    "        print('Handedness:', results.multi_handedness)\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        \n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            featurelist.append(hand_landmarks)\n",
    "            print('hand_landmarks:', hand_landmarks)\n",
    "            print(\n",
    "               f'Index finger tip coordinates: (',\n",
    "               f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "               f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "            )\n",
    "            '''\n",
    "            mp_drawing.draw_landmarks(\n",
    "               annotated_image,\n",
    "               hand_landmarks,\n",
    "               mp_hands.HAND_CONNECTIONS,\n",
    "               mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "               mp_drawing_styles.get_default_hand_connections_style())\n",
    "            '''\n",
    "        #cv2.imwrite(\n",
    "        #'/Users/bridgetliu/project/mais2021/tmp'+str(idx)+'.png', cv2.flip(annotated_image, 1))\n",
    "        all_img_features.append(featurelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a73d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ede870",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(all_img_features,dtype = object)\n",
    "savetxt('k.csv', tmp,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ace58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c61638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef0363c2",
   "metadata": {},
   "source": [
    "# for multiple folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/bridgetliu/project/mais2021/archive/asl_alphabet_train/asl_alphabet_train/'\n",
    "count = 0 \n",
    "names = []\n",
    "folders = []\n",
    "for root, subdirectories, files in os.walk(directory):\n",
    "    for subdirectory in subdirectories:\n",
    "        count +=1\n",
    "        #print(os.path.join(root, subdirectory))\n",
    "        # loop thru all the files in a folder \n",
    "        filenames = []\n",
    "        directory = os.path.join(root, subdirectory)\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                filenames.append(os.path.join(directory, filename))\n",
    "            else:\n",
    "                continue\n",
    "        names.append(filenames)\n",
    "        folders.append(subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f005b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldersubdirectory in subdirectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5124c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "\n",
    "for i in range(29):\n",
    "    IMAGE_FILES = names[i]\n",
    "    all_img_features = []\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            print(\"here\")\n",
    "            featurelist = []\n",
    "            # Read an image, flip it around y-axis for correct handedness output\n",
    "            image = cv2.flip(cv2.imread(file), 1)\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            #results = hands.process(image)\n",
    "            #Print handedness and draw hand landmarks on the image.\n",
    "            featurelist.append(folders[i])\n",
    "            featurelist.append(results.multi_handedness)\n",
    "            print('Handedness:', results.multi_handedness)\n",
    "            if not results.multi_hand_landmarks:\n",
    "                continue\n",
    "        \n",
    "            image_height, image_width, _ = image.shape\n",
    "            annotated_image = image.copy()\n",
    "        \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                featurelist.append(hand_landmarks)\n",
    "                print('hand_landmarks:', hand_landmarks)\n",
    "                print(\n",
    "                   f'Index finger tip coordinates: (',\n",
    "                   f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "                   f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "                )\n",
    "            '''\n",
    "            mp_drawing.draw_landmarks(\n",
    "               annotated_image,\n",
    "               hand_landmarks,\n",
    "               mp_hands.HAND_CONNECTIONS,\n",
    "               mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "               mp_drawing_styles.get_default_hand_connections_style())\n",
    "            '''\n",
    "            #cv2.imwrite(\n",
    "            #'/Users/bridgetliu/project/mais2021/tmp'+str(idx)+'.png', cv2.flip(annotated_image, 1))\n",
    "            all_img_features.append(featurelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(all_img_features,dtype = object)\n",
    "savetxt('features.csv', tmp,fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
